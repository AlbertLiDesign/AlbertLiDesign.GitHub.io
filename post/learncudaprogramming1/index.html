<!DOCTYPE html>
<html>
        <head>
        <meta name="viewport" content="width=device-width,minimum-scale=1,maximum-scale=1,initial-scale=1,user-scalable=no" />
        <meta charset="utf-8">
        <title>Learn CUDA Programming(1) | AlbertLiDesign</title>
        <link rel="stylesheet" href="https://albertlidesign.github.io/styles/main.css">
        <link rel="stylesheet" href="https://at.alicdn.com/t/font_1306644_jwtuc2zzbrd.css">
        <link href="https://cdn.bootcss.com/animate.css/3.7.2/animate.min.css" rel="stylesheet">
         <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
        <script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script>
         <script src="https://cdn.bootcss.com/highlight.js/9.15.10/highlight.min.js"></script>
         <script >hljs.initHighlightingOnLoad();</script>

    </head>
    <body>
              <header class="header mdui-m-b-5">      
            <div class="container  ">
                <div class="index-title animated fadeInDown mdui-text-center mdui-text-color-white mdui-m-b-2" style="animation-delay: 0.2s"><a href="https://albertlidesign.github.io">AlbertLiDesign</a></div>
                <div class="mdui-text-color-white animated fadeInDown mdui-text-center  mdui-m-b-3" style="animation-delay: 0.4s">Welcome to Albert Li Design. This is a blog for random braindumps on my programming adventures, graphics and design research, some of my more serious writings and other interesting things.</div>
           
            <nav id="nav" class="mdui-text-center animated fadeInDown" style="animation-delay: 0.6s">
                   
                            <li><a href="/">Home</a>
                                <span class="nav-style top"></span>
                                <span class="nav-style bottom"></span>
                                <span class="nav-style left"></span>
                                <span class="nav-style right"></span>
                                </li>
                    
                            <li><a href="/archives">Archives</a>
                                <span class="nav-style top"></span>
                                <span class="nav-style bottom"></span>
                                <span class="nav-style left"></span>
                                <span class="nav-style right"></span>
                                </li>
                    
                            <li><a href="/tags">Tags</a>
                                <span class="nav-style top"></span>
                                <span class="nav-style bottom"></span>
                                <span class="nav-style left"></span>
                                <span class="nav-style right"></span>
                                </li>
                    
                            <li><a href="/post/about">About</a>
                                <span class="nav-style top"></span>
                                <span class="nav-style bottom"></span>
                                <span class="nav-style left"></span>
                                <span class="nav-style right"></span>
                                </li>
                    
                  </nav>
                </div>
        </header>
        <div class="mdui-container ">
                <div class="mdui-row">
                        <div class="mdui-col-md-8 mdui-col-offset-md-2 ">
                                <article class="mdui-p-a-2 post animated fadeIn" style="animation-delay: 0.8s;animation-duration: 2s">
                                    <div class="post-title  mdui-m-b-1">Learn CUDA Programming(1)</div>
                                    <div class="mdui-typo-body-2 mdui-m-b-2" datetime="2020-03-31 18:38:44">2020-03-31 / 8 min read</div>
                                    <div class="mdui-m-b-2 mdui-typo post-neirong"><h2 id="access-the-power-of-gpu">Access the Power of GPU</h2>
<ul>
<li>一般有三种方法来实现加速：<strong>Libraries</strong> or <strong>OpenACC</strong> or <strong>Programming Languages</strong></li>
<li>函数库：</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://upload-images.jianshu.io/upload_images/19551947-b5c9213b0550784d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="" loading="lazy"></figure>
<p>例如：</p>
<p>cuBLAS: 线性代数库</p>
<p>cuSPARSE: 稀疏矩阵的线性代数库</p>
<p>cuDNN: 深度神经网络</p>
<h2 id="gpu-architecture">GPU Architecture</h2>
<h3 id="异构计算heterogeneous-computing">异构计算(Heterogeneous Computing)</h3>
<h4 id="terminology">Terminology:</h4>
<ul>
<li><strong>Host</strong>: The CPU and tis memory(host memory) <strong>主机端(CPU)</strong></li>
<li><strong>Device</strong>: The GPU and its memory(device memory) <strong>设备端(GPU)</strong></li>
</ul>
<h4 id="cpu与gpu的简易架构图">CPU与GPU的简易架构图</h4>
<figure data-type="image" tabindex="2"><img src="https://upload-images.jianshu.io/upload_images/19551947-4281687860e63623.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="" loading="lazy"></figure>
<ul>
<li>CPU有很多逻辑控制单元，而GPU有很多处理核心</li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://upload-images.jianshu.io/upload_images/19551947-d979df42fb4b03c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="" loading="lazy"></figure>
<ul>
<li>CPU是缓存优化的处理器，缓存特别大，而且有很多控制单元</li>
<li>GPU是一个并行吞吐优化的处理器，计算核心特别多</li>
<li>因此我们知道，GPU的单精度处理能力比CPU快很多的原因其实就是GPU将更多的晶体管用于了计算而不是缓存</li>
</ul>
<h4 id="程序的开发中如何选择cpu和gpu">程序的开发中如何选择CPU和GPU</h4>
<figure data-type="image" tabindex="4"><img src="https://upload-images.jianshu.io/upload_images/19551947-38f6a35193544add.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="" loading="lazy"></figure>
<ul>
<li>从图中可以看到CPU的缓存延迟非常短，这也对应它的架构里有很多复杂的逻辑控制</li>
<li>GPU则不同，图中的W是warp，1 warp = 32 Threads，GPU是以warp为单位进行切换的。我们可以通过海量的线程的切换来对缓存延迟做隐藏，如果你的程序是计算密集型的，而且有很好的并行特性，那么gpu是更好的选择。</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://upload-images.jianshu.io/upload_images/19551947-9796dc4f83cd657e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="" loading="lazy"></figure>
<ul>
<li>GPU的架构有两个部分组成，第一部分是计算单元，第二部分是内存单元</li>
<li>图中的绿色部分就是一个CUDA Core</li>
<li>从图中可以看到，GPU和CPU是通过PCle进行链接的</li>
<li>一个GPU有很多SM（流多处理器）组成，每一个SM有很多核，因此有越多的SM，那么GPU就能在同一时间内处理更多的任务。</li>
</ul>
<h4 id="sm的架构">SM的架构</h4>
<figure data-type="image" tabindex="6"><img src="https://upload-images.jianshu.io/upload_images/19551947-14cdbb0d27ac7b91.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/400" alt="" loading="lazy"></figure>
<ul>
<li>Kepler架构中的SM称为SMX，表示处理器更强劲，其逻辑控制单元是一个整体，控制192个CUDA Cores</li>
<li>Maxwell架构中的SM称为SMM，其逻辑控制单元有4个，每个控制32个CUDA Cores</li>
<li>可以简单认为，一个SMM中包含了4个SMX，这样的话就避免了因为逻辑控制单元过少而造成核心的冗余，效率更高。从架构上来看，Maxwell一个CUDA核心相比于Kepler提升了35%</li>
</ul>
<h4 id="memory-hierarchy">Memory Hierarchy</h4>
<figure data-type="image" tabindex="7"><img src="https://upload-images.jianshu.io/upload_images/19551947-97024b3209a40dc5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="" loading="lazy"></figure>
<p>因为经常要跟内存打交道，所以需要对GPU的内存架构非常熟悉，GPU的架构分为三个层次，如图所示，和CPU类似，可以看做成一个金字塔，从下往上越来越快，首先是Global Memory，有很大的内存空间，它的空间很大，但是缓存延迟很高，因此我们需要加入一个缓存，称之为L2缓存，GPU的缓存要像Global Memory一样读取数据的话，首先我们要看这些数据是否在L2中已经有缓存，有的话称之为缓存命中，这样就不用再从Global Memory里面读数据，这样就加快了读写。L2缓存是多个缓存所共享的。再上面有很多寄存器，L1缓存等。对于不同的内存有不同的使用和优化方案。</p>
<h4 id="gpu-in-computer-system">GPU in Computer System</h4>
<figure data-type="image" tabindex="8"><img src="https://upload-images.jianshu.io/upload_images/19551947-d55db112286d14d5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/400" alt="" loading="lazy"></figure>
<h2 id="cuda-programming-basics">CUDA Programming Basics</h2>
<h3 id="配置cuda开发环境">配置CUDA开发环境</h3>
<figure data-type="image" tabindex="9"><img src="https://upload-images.jianshu.io/upload_images/19551947-a0db2c87ff22deea.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="" loading="lazy"></figure>
<ul>
<li>注意如果使用C/C++进行开发的话，我们使用的是NVCC的编译器</li>
</ul>
<h3 id="heterogeneous-computing-异构编程">Heterogeneous Computing 异构编程</h3>
<ul>
<li>
<p>一般我们把GPU运行的程序构造成一个函数，在我们需要的时候进行调用，这个函数就是在GPU上运行</p>
</li>
<li>
<p>这个函数的之前和之后都是在CPU上单线程运行的，因此我们把整个程序分为：顺序执行，并行执行，顺序执行<br>
<img src="https://upload-images.jianshu.io/upload_images/19551947-52d9674b54ab755b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="" loading="lazy"></p>
</li>
<li>
<p>顺序执行就是利用CPU的一个线程来执行</p>
</li>
<li>
<p>并行执行就是用GPU的多线程来进行计算</p>
</li>
<li>
<p>因此如果一部分功能是计算密集型的，我们就可以把它写成一个函数，对它进行并行，并不是把所有的代码都在GPU上运行，而是把需要的部分放到GPU上</p>
</li>
</ul>
<h4 id="cuda-kernels">CUDA Kernels</h4>
<p>这里我们讲解一个概念，我们要将一部分代码在gpu上运行，这部分代码是一个函数，我们称为一个<strong>kernel（核函数）</strong>，CPU（Host）执行functions，GPU（Device）执行kernels。</p>
<h3 id="hello-world">Hello World</h3>
<pre><code>//hello_world.c
#include &lt;stdio.h&gt;

void hello_world_kernel()
{
    printf(&quot;Hello World\n&quot;);
}

int main()
{
    hello_world_kernel();
}
</code></pre>
<p>Compile &amp; Run:<br>
gcc hello_world.c<br>
./a.out</p>
<p>在GPU上执行:</p>
<pre><code>//hello_world.cu
#include &lt;stdio.h&gt;

_global_ hello_world_kernel()
{
    printf(&quot;Hello World\n&quot;);
}

int main()
{
    hello_world_kernel&lt;&lt;&lt;1.1&gt;&gt;&gt;();
}
</code></pre>
<p>Compile &amp; Run:<br>
nvcc hello_world.cu<br>
./a.out</p>
<h4 id="不同之处">不同之处</h4>
<ul>
<li>文件后缀名改为.cu</li>
<li>_global_表示了该函数为一个核函数，标识这个函数会在gpu上运行</li>
<li>“&lt;&lt;&lt;...,...&gt;&gt;&gt;”具体含义是GPU中的一个配置</li>
<li>编译器改为nvcc</li>
</ul>
<h3 id="gpu-memory-management">GPU memory management</h3>
<p>hello world程序非常简单明了，但是在编程过程中我们经常要和内存打交道，那么如何进行GPU内存管理呢？</p>
<p>我们很熟悉对CPU的内存管理，我们会使用</p>
<pre><code>malloc();//动态分配内存
memset();//对空间进行初始化
free();//释放一段内存
</code></pre>
<p>对应于，在GPU中也有类似的函数，它们分别是</p>
<pre><code>cudaMalloc(void** pointer, sie_t nbytes);//pointer指定空间，大小是nbytes
cudaMemset(void* pointer, int value, size_t count);
cudaFree(void* pointer);
</code></pre>
<p>例如：</p>
<pre><code>int nbytes = 1024*sizeof(int);
int* d_a = 0;
cudaMalloc((void**)&amp;d_a, nbytes);
cudaMemset(d_a, 0, nbytes);
cudaFree(d_a);
</code></pre>
<p>因此一定要分清楚，哪部分数据在cpu上，哪部分数据在gpu上</p>
<h4 id="data-copies">Data Copies</h4>
<pre><code>__host__ cudaMemcpy(void* dst, void* src, size_t nbytes, cudaMemcpyKind direction);
</code></pre>
<ul>
<li>__global__是在gpu上进行的，__host__就是在cpu上执行</li>
<li>四个形参：拷贝目的指针，拷贝原指针，拷贝大小，拷贝方向</li>
<li>线程阻塞的，拷贝不完成，cpu不会执行下面的代码</li>
<li>常见拷贝方向有：cudaMemcpyHostToDevice（CPU到GPU）、cudaMemcpyDeviceToHost（GPU到CPU）、cudaMemcpyDeviceToDevice（GPU到GPU）</li>
<li>设定拷贝方向时，需要注意src和dst的指针是CPU的还是GPU的，要和拷贝方向一致</li>
<li>上述函数为线程阻塞的，同样还有一个异步的函数：cudaMemcpyAsync();</li>
</ul>
<h4 id="三步流程">三步流程</h4>
<figure data-type="image" tabindex="10"><img src="https://upload-images.jianshu.io/upload_images/19551947-ce6c188d28db2666.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="" loading="lazy"></figure>
<p>第一步：通过调用cudaMemcpy函数将CPU中的数据拷贝到GPU中，通过PCI Bus，方向就是HostToDevice</p>
<figure data-type="image" tabindex="11"><img src="https://upload-images.jianshu.io/upload_images/19551947-d4b08ea810fd7bf2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="" loading="lazy"></figure>
<p>第二步：通过CPU启动kernel核函数，然后开始一个并行计算</p>
<pre><code>Kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;();
</code></pre>
<figure data-type="image" tabindex="12"><img src="https://upload-images.jianshu.io/upload_images/19551947-48077f231db74847.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="" loading="lazy"></figure>
<p>第三步：计算完以后，再调用cudaMemcpy将数据从GPU端拷贝到CPU端，方向是DeviceToHost</p>
<p>例子:</p>
<p>代码分为五个步骤：</p>
<ul>
<li>在CPU端分配n个整型变量的空间</li>
<li>在GPU端分配n个整型变量的空间</li>
<li>初始化GPU内存为0</li>
<li>将数据从GPU拷贝到CPU</li>
<li>打印变量</li>
</ul>
<pre><code>#include&lt;stdio.h&gt;

int main()
{
    int dimx = 16;
    int num_bytes = dimx * sizeof(int);
    int *d_a = 0, *h_a = 0;//设备端和主机端的指针
    
    //在CPU端分配n个整型变量的空间
    h_a = (int*)malloc(num_bytes);
    //在GPU端分配n个整型变量的空间
    cudaMalloc((void**) &amp;d_a, num_bytes);
    
    if(0 == h_a || 0 == d_a)
    {
        printf(&quot;Couldn't allocate memory\n&quot;);
        return 1;
    }
    
    //初始化GPU内存为0
    cudaMemset(d_a,0,num_bytes);
    
    //将数据从GPU拷贝到CPU
    cudaMemcpy(h_a, d_a, num_bytes, cudaMemcpyDeviceToHost);
    
    //打印变量
    for(int i=0; i &lt; dimx; i++)
    {
        printf(&quot;%d\t&quot;, h_a[i]);
    }
    free(h_a);//主机端释放
    cudaFree(d_a);//设备端释放
    return 0;
}
</code></pre>
<ul>
<li>这里注意，cudaMemcpy是CPU阻塞的，也就是说，不执行完该函数CPU就不会一直向下执行。如果换成一个异步的版本，CPU会在拷贝还没有完成的时候就开始打印，打印的时候很多是错误的。</li>
</ul>
<p>上面的示例代码缺少了GPU上面的并行计算，那么我们下一面将开始讲解如何写Kernel函数。</p>
</div>
                                    <div class="mdui-divider mdui-m-b-2"></div>
                                    <div class="mdui-row-xs-2 post-fenye">
                                       
                                        <div class="mdui-col"> <div class="mdui-text-left"><a href="https://albertlidesign.github.io/post/learncudaprogramming2/">Learn CUDA Programming(2)</a></div></div>
                                        

                                        
                                        <div class="mdui-col"><div class="mdui-text-right "><a href="https://albertlidesign.github.io/post/careerchanging/">设计师转行做开发？来看看四位过来人怎么说</a></div> </div>
                                       
                                      </div>
                                   
                                    <div class="mdui-divider mdui-m-t-2 mdui-m-b-2"></div>
                                    
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: '',
    clientSecret: '',
    repo: '',
    owner: '',
    admin: [''],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          
          
        
                                     <script src="https://albertlidesign.github.io/media/scripts/Valine.min.js"></script>
 <div class="comment"></div>

<script>
      new Valine({
            el: '.comment',



            path: window.location.pathname,
            pageSize: 30,
            avatar:'mm', 
       })
    </script> 
<script>
    if(window.location.hash){
        var checkExist = setInterval(function() {
           if ($(window.location.hash).length) {
              $('html, body').animate({scrollTop: $(window.location.hash).offset().top-90}, 1000);
              clearInterval(checkExist);
           }
        }, 100);
    }
</script>
                                </article>

                                    
                        </div>
                      </div>
    
                

              </div>
                    <footer class="footer mdui-m-t-5 mdui-text-center">
               <nav class="social-links">
                      <ul>
                      
                      
                           
                      
                           
                      	
                        <li class="social-link"><a href="https://github.com/AlbertLiDesign" target="_blank"><i class="iconfont icon-github"></i></a></li>
                          
                           
                      
                           
                      
                           
                      
                           
                      
                           
                      
                           
                      
                           
                      
                           
                      
                           
                      
                           
                      </ul>
                    </nav>
                    <div class="copyright">
                      <p>Powered by <a href="https://github.com/AlbertLiDesign" target="_blank">AlbertLiDesign</a> <br/> Theme <a href="https://github.com/alterfang/gridea-theme-song/" target="_blank"  title="宋"  >Song</a> by <a href="https://shanbu.fun/" target="_blank"  title="山卜方" >shanbufun</a> </p>
                  </div>
                  
              </footer>
    </body>
</html>